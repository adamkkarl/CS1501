Adam Karl
I implemented the user history pretty simply using the built in Java Map utility. Using a map makes sense because it's iterable, and we're often looking for a certain frequency that a word has been used in the past, and storing the string-frequency as a key-value pair is an obvious solution. This approach also makes it easy to write the history to a .txt file with each line in my user_history.txt taking the format (string) (freq). The major downside of this approach is that the entries are not sorted, resulting in a ?(n) linear search time with respect to the number of unique words in the user history (insert and update are also linear since they both require a search of the data structure). 

If our goal was to make the user history as efficient as possible, I would heavily modify my DLB and it's methods, including adding a new field so that any valid word node also kept track of the word's frequency. This way I could have a separate dlb for the user history
However, this would take a significant amount of additional development time as my DLB was not originally designed with this in mind. Alternate methods would need to be implemented to return not only the first 5 strings starting with a prefix (dictionary suggestions) but also to find and return the 5 strings with the highest frequency out of ALL strings starting with that prefix. In the average case, this would be a much better solution than the one I've provided, although in the worst case would still be ?(n) when every string in history starts with the given prefix. Ultimately, the additional development time dissuaded me from implementing it for this lab.

I also considered using parallel, alphabetically-sorted ArrayLists to store the strings and frequencies, with the upside being faster average search time utilizing a binary search. Note that when generating predictions, this approach would not improve performance in the worst case, as if the user had only entered "a" so far, and every string in the dictionary started with "a" it would still have to parse through every single string checking the frequencies. Another downside of such an approach is when adding a new string in the middle, all other strings would have to be "shifted over," resulting in a ?(n) insert time.

In the end, mapping the string to the frequency was extremely quick to program, and still runs in a passable linear time, which should only become an issue after thousands or millions of words are added to the history. 
